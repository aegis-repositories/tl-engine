# ðŸ‘· Kubernetes + Engine Worker

## ðŸ“Š Â¿CÃ³mo K8s gestiona Workers?

```mermaid
graph TB
    A[RabbitMQ<br/>Queue] --> B[Worker Pod 1]
    A --> C[Worker Pod 2]
    A --> D[Worker Pod 3]
    
    B --> E[Process Task]
    C --> E
    D --> E
    
    style A fill:#ff6600
    style B fill:#4a90e2
    style C fill:#4a90e2
    style D fill:#4a90e2
```

## ðŸ—ï¸ Deployment de Workers

### **ConfiguraciÃ³n BÃ¡sica:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: engine-worker
spec:
  replicas: 3  # 3 workers consumiendo de la misma queue
  selector:
    matchLabels:
      app: engine-worker
  template:
    metadata:
      labels:
        app: engine-worker
    spec:
      containers:
      - name: worker
        image: tl-engine:latest
        command: ["python", "worker.py"]
        env:
        - name: AMQP_URL
          valueFrom:
            secretKeyRef:
              name: rabbitmq-secret
              key: AMQP_URL
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: postgresql-secret
              key: DATABASE_URL
```

**QuÃ© hace:**
- âœ… Crea 3 pods de worker
- âœ… Cada pod consume de RabbitMQ
- âœ… Load balancing automÃ¡tico de mensajes

---

## ðŸ”„ Consumo de Mensajes

### **CÃ³mo funciona:**

```mermaid
sequenceDiagram
    participant Q as RabbitMQ Queue
    participant W1 as Worker Pod 1
    participant W2 as Worker Pod 2
    participant W3 as Worker Pod 3
    
    Q->>W1: Message 1
    Q->>W2: Message 2
    Q->>W3: Message 3
    W1->>Q: ACK
    W2->>Q: ACK
    W3->>Q: ACK
```

**RabbitMQ distribuye mensajes:**
- Round-robin entre workers
- Si un worker falla, mensaje vuelve a la queue
- Otro worker lo procesa

---

## ðŸ”§ ConfiguraciÃ³n Avanzada

### **Resource Limits:**

```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "250m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```

**QuÃ© hace:**
- âœ… Reserva recursos mÃ­nimos
- âœ… Limita recursos mÃ¡ximos
- âœ… Evita que un worker consuma todo

---

### **Health Checks:**

```yaml
livenessProbe:
  exec:
    command:
    - /bin/sh
    - -c
    - "ps aux | grep worker.py | grep -v grep"
  initialDelaySeconds: 30
  periodSeconds: 10

readinessProbe:
  exec:
    command:
    - /bin/sh
    - -c
    - "python -c 'import pika; pika.BlockingConnection(pika.URLParameters(\"$AMQP_URL\"))'"
  initialDelaySeconds: 10
  periodSeconds: 5
```

**QuÃ© hace:**
- âœ… Liveness: Verifica que el worker estÃ¡ corriendo
- âœ… Readiness: Verifica que puede conectar a RabbitMQ

---

## ðŸ”„ Escalado de Workers

### **Manual:**
```bash
kubectl scale deployment engine-worker --replicas=10
```

### **AutomÃ¡tico (HPA):**
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: engine-worker-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: engine-worker
  minReplicas: 3
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

**QuÃ© hace:**
- âœ… Escala workers basado en CPU
- âœ… MÃ¡s workers = mÃ¡s mensajes procesados
- âœ… Auto-scaling segÃºn carga

---

## ðŸŽ¯ Estrategias de Escalado

### **Basado en Queue Length:**

```yaml
# Usar custom metrics (requiere Prometheus)
metrics:
- type: Pods
  pods:
    metric:
      name: rabbitmq_queue_length
    target:
      type: AverageValue
      averageValue: "10"  # Escalar si queue > 10 mensajes
```

**QuÃ© hace:**
- âœ… Escala cuando hay muchos mensajes en queue
- âœ… MÃ¡s preciso que CPU
- âœ… Requiere mÃ©tricas custom

---

## ðŸ”§ Worker Implementation

### **CÃ³digo del Worker:**

```python
# worker.py
import pika
import json
import os

AMQP_URL = os.environ.get('AMQP_URL')

connection = pika.BlockingConnection(pika.URLParameters(AMQP_URL))
channel = connection.channel()

channel.queue_declare(queue='engine:tasks', durable=True)

def process_task(ch, method, properties, body):
    task = json.loads(body)
    # Procesar tarea
    result = execute_task(task)
    # ACK
    ch.basic_ack(delivery_tag=method.delivery_tag)

channel.basic_qos(prefetch_count=1)  # Un mensaje por worker
channel.basic_consume(
    queue='engine:tasks',
    on_message_callback=process_task
)

channel.start_consuming()
```

**QuÃ© hace:**
- âœ… Conecta a RabbitMQ
- âœ… Consume mensajes de la queue
- âœ… Procesa tareas
- âœ… ACK cuando termina

---

## âœ… Resumen

**K8s gestiona:**
- âœ… Despliegue de worker pods
- âœ… Escalado automÃ¡tico
- âœ… Health checks
- âœ… Restart en fallos
- âœ… Resource limits

**El worker:**
- âœ… Solo necesita consumir de RabbitMQ
- âœ… Procesar mensajes
- âœ… ACK cuando termina
- âœ… K8s distribuye carga automÃ¡ticamente





